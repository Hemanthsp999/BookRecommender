{"ast":null,"code":"/*\n\tMIT License http://www.opensource.org/licenses/mit-license.php\n*/\n\n\"use strict\";\n\nconst {\n  constants\n} = require(\"buffer\");\nconst {\n  pipeline\n} = require(\"stream\");\nconst {\n  createBrotliCompress,\n  createBrotliDecompress,\n  createGzip,\n  createGunzip,\n  constants: zConstants\n} = require(\"zlib\");\nconst createHash = require(\"../util/createHash\");\nconst {\n  dirname,\n  join,\n  mkdirp\n} = require(\"../util/fs\");\nconst memoize = require(\"../util/memoize\");\nconst SerializerMiddleware = require(\"./SerializerMiddleware\");\n\n/** @typedef {typeof import(\"../util/Hash\")} Hash */\n/** @typedef {import(\"../util/fs\").IntermediateFileSystem} IntermediateFileSystem */\n/** @typedef {import(\"./types\").BufferSerializableType} BufferSerializableType */\n\n/*\nFormat:\n\nFile -> Header Section*\n\nVersion -> u32\nAmountOfSections -> u32\nSectionSize -> i32 (if less than zero represents lazy value)\n\nHeader -> Version AmountOfSections SectionSize*\n\nBuffer -> n bytes\nSection -> Buffer\n\n*/\n\n// \"wpc\" + 1 in little-endian\nconst VERSION = 0x01637077;\nconst WRITE_LIMIT_TOTAL = 0x7fff0000;\nconst WRITE_LIMIT_CHUNK = 511 * 1024 * 1024;\n\n/**\n * @param {Buffer[]} buffers buffers\n * @param {string | Hash} hashFunction hash function to use\n * @returns {string} hash\n */\nconst hashForName = (buffers, hashFunction) => {\n  const hash = createHash(hashFunction);\n  for (const buf of buffers) hash.update(buf);\n  return (/** @type {string} */hash.digest(\"hex\")\n  );\n};\nconst COMPRESSION_CHUNK_SIZE = 100 * 1024 * 1024;\nconst DECOMPRESSION_CHUNK_SIZE = 100 * 1024 * 1024;\nconst writeUInt64LE = Buffer.prototype.writeBigUInt64LE ? (buf, value, offset) => {\n  buf.writeBigUInt64LE(BigInt(value), offset);\n} : (buf, value, offset) => {\n  const low = value % 0x100000000;\n  const high = (value - low) / 0x100000000;\n  buf.writeUInt32LE(low, offset);\n  buf.writeUInt32LE(high, offset + 4);\n};\nconst readUInt64LE = Buffer.prototype.readBigUInt64LE ? (buf, offset) => {\n  return Number(buf.readBigUInt64LE(offset));\n} : (buf, offset) => {\n  const low = buf.readUInt32LE(offset);\n  const high = buf.readUInt32LE(offset + 4);\n  return high * 0x100000000 + low;\n};\n\n/**\n * @typedef {Object} SerializeResult\n * @property {string | false} name\n * @property {number} size\n * @property {Promise=} backgroundJob\n */\n\n/**\n * @param {FileMiddleware} middleware this\n * @param {BufferSerializableType[] | Promise<BufferSerializableType[]>} data data to be serialized\n * @param {string | boolean} name file base name\n * @param {function(string | false, Buffer[], number): Promise<void>} writeFile writes a file\n * @param {string | Hash} hashFunction hash function to use\n * @returns {Promise<SerializeResult>} resulting file pointer and promise\n */\nconst serialize = async function (middleware, data, name, writeFile) {\n  let hashFunction = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : \"md4\";\n  /** @type {(Buffer[] | Buffer | SerializeResult | Promise<SerializeResult>)[]} */\n  const processedData = [];\n  /** @type {WeakMap<SerializeResult, function(): any | Promise<any>>} */\n  const resultToLazy = new WeakMap();\n  /** @type {Buffer[]} */\n  let lastBuffers = undefined;\n  for (const item of await data) {\n    if (typeof item === \"function\") {\n      if (!SerializerMiddleware.isLazy(item)) throw new Error(\"Unexpected function\");\n      if (!SerializerMiddleware.isLazy(item, middleware)) {\n        throw new Error(\"Unexpected lazy value with non-this target (can't pass through lazy values)\");\n      }\n      lastBuffers = undefined;\n      const serializedInfo = SerializerMiddleware.getLazySerializedValue(item);\n      if (serializedInfo) {\n        if (typeof serializedInfo === \"function\") {\n          throw new Error(\"Unexpected lazy value with non-this target (can't pass through lazy values)\");\n        } else {\n          processedData.push(serializedInfo);\n        }\n      } else {\n        const content = item();\n        if (content) {\n          const options = SerializerMiddleware.getLazyOptions(item);\n          processedData.push(serialize(middleware, content, options && options.name || true, writeFile, hashFunction).then(result => {\n            /** @type {any} */item.options.size = result.size;\n            resultToLazy.set(result, item);\n            return result;\n          }));\n        } else {\n          throw new Error(\"Unexpected falsy value returned by lazy value function\");\n        }\n      }\n    } else if (item) {\n      if (lastBuffers) {\n        lastBuffers.push(item);\n      } else {\n        lastBuffers = [item];\n        processedData.push(lastBuffers);\n      }\n    } else {\n      throw new Error(\"Unexpected falsy value in items array\");\n    }\n  }\n  /** @type {Promise<any>[]} */\n  const backgroundJobs = [];\n  const resolvedData = (await Promise.all( /** @type {Promise<Buffer[] | Buffer | SerializeResult>[]} */\n  processedData)).map(item => {\n    if (Array.isArray(item) || Buffer.isBuffer(item)) return item;\n    backgroundJobs.push(item.backgroundJob);\n    // create pointer buffer from size and name\n    const name = /** @type {string} */item.name;\n    const nameBuffer = Buffer.from(name);\n    const buf = Buffer.allocUnsafe(8 + nameBuffer.length);\n    writeUInt64LE(buf, item.size, 0);\n    nameBuffer.copy(buf, 8, 0);\n    const lazy = resultToLazy.get(item);\n    SerializerMiddleware.setLazySerializedValue(lazy, buf);\n    return buf;\n  });\n  /** @type {number[]} */\n  const lengths = [];\n  for (const item of resolvedData) {\n    if (Array.isArray(item)) {\n      let l = 0;\n      for (const b of item) l += b.length;\n      while (l > 0x7fffffff) {\n        lengths.push(0x7fffffff);\n        l -= 0x7fffffff;\n      }\n      lengths.push(l);\n    } else if (item) {\n      lengths.push(-item.length);\n    } else {\n      throw new Error(\"Unexpected falsy value in resolved data \" + item);\n    }\n  }\n  const header = Buffer.allocUnsafe(8 + lengths.length * 4);\n  header.writeUInt32LE(VERSION, 0);\n  header.writeUInt32LE(lengths.length, 4);\n  for (let i = 0; i < lengths.length; i++) {\n    header.writeInt32LE(lengths[i], 8 + i * 4);\n  }\n  /** @type {Buffer[]} */\n  const buf = [header];\n  for (const item of resolvedData) {\n    if (Array.isArray(item)) {\n      for (const b of item) buf.push(b);\n    } else if (item) {\n      buf.push(item);\n    }\n  }\n  if (name === true) {\n    name = hashForName(buf, hashFunction);\n  }\n  let size = 0;\n  for (const b of buf) size += b.length;\n  backgroundJobs.push(writeFile(name, buf, size));\n  return {\n    size,\n    name,\n    backgroundJob: backgroundJobs.length === 1 ? backgroundJobs[0] : Promise.all(backgroundJobs)\n  };\n};\n\n/**\n * @param {FileMiddleware} middleware this\n * @param {string | false} name filename\n * @param {function(string | false): Promise<Buffer[]>} readFile read content of a file\n * @returns {Promise<BufferSerializableType[]>} deserialized data\n */\nconst deserialize = async (middleware, name, readFile) => {\n  const contents = await readFile(name);\n  if (contents.length === 0) throw new Error(\"Empty file \" + name);\n  let contentsIndex = 0;\n  let contentItem = contents[0];\n  let contentItemLength = contentItem.length;\n  let contentPosition = 0;\n  if (contentItemLength === 0) throw new Error(\"Empty file \" + name);\n  const nextContent = () => {\n    contentsIndex++;\n    contentItem = contents[contentsIndex];\n    contentItemLength = contentItem.length;\n    contentPosition = 0;\n  };\n  /**\n   * @param {number} n number of bytes to ensure\n   */\n  const ensureData = n => {\n    if (contentPosition === contentItemLength) {\n      nextContent();\n    }\n    while (contentItemLength - contentPosition < n) {\n      const remaining = contentItem.slice(contentPosition);\n      let lengthFromNext = n - remaining.length;\n      const buffers = [remaining];\n      for (let i = contentsIndex + 1; i < contents.length; i++) {\n        const l = contents[i].length;\n        if (l > lengthFromNext) {\n          buffers.push(contents[i].slice(0, lengthFromNext));\n          contents[i] = contents[i].slice(lengthFromNext);\n          lengthFromNext = 0;\n          break;\n        } else {\n          buffers.push(contents[i]);\n          contentsIndex = i;\n          lengthFromNext -= l;\n        }\n      }\n      if (lengthFromNext > 0) throw new Error(\"Unexpected end of data\");\n      contentItem = Buffer.concat(buffers, n);\n      contentItemLength = n;\n      contentPosition = 0;\n    }\n  };\n  /**\n   * @returns {number} value value\n   */\n  const readUInt32LE = () => {\n    ensureData(4);\n    const value = contentItem.readUInt32LE(contentPosition);\n    contentPosition += 4;\n    return value;\n  };\n  /**\n   * @returns {number} value value\n   */\n  const readInt32LE = () => {\n    ensureData(4);\n    const value = contentItem.readInt32LE(contentPosition);\n    contentPosition += 4;\n    return value;\n  };\n  /**\n   * @param {number} l length\n   * @returns {Buffer} buffer\n   */\n  const readSlice = l => {\n    ensureData(l);\n    if (contentPosition === 0 && contentItemLength === l) {\n      const result = contentItem;\n      if (contentsIndex + 1 < contents.length) {\n        nextContent();\n      } else {\n        contentPosition = l;\n      }\n      return result;\n    }\n    const result = contentItem.slice(contentPosition, contentPosition + l);\n    contentPosition += l;\n    // we clone the buffer here to allow the original content to be garbage collected\n    return l * 2 < contentItem.buffer.byteLength ? Buffer.from(result) : result;\n  };\n  const version = readUInt32LE();\n  if (version !== VERSION) {\n    throw new Error(\"Invalid file version\");\n  }\n  const sectionCount = readUInt32LE();\n  const lengths = [];\n  let lastLengthPositive = false;\n  for (let i = 0; i < sectionCount; i++) {\n    const value = readInt32LE();\n    const valuePositive = value >= 0;\n    if (lastLengthPositive && valuePositive) {\n      lengths[lengths.length - 1] += value;\n    } else {\n      lengths.push(value);\n      lastLengthPositive = valuePositive;\n    }\n  }\n  const result = [];\n  for (let length of lengths) {\n    if (length < 0) {\n      const slice = readSlice(-length);\n      const size = Number(readUInt64LE(slice, 0));\n      const nameBuffer = slice.slice(8);\n      const name = nameBuffer.toString();\n      result.push(SerializerMiddleware.createLazy(memoize(() => deserialize(middleware, name, readFile)), middleware, {\n        name,\n        size\n      }, slice));\n    } else {\n      if (contentPosition === contentItemLength) {\n        nextContent();\n      } else if (contentPosition !== 0) {\n        if (length <= contentItemLength - contentPosition) {\n          result.push(Buffer.from(contentItem.buffer, contentItem.byteOffset + contentPosition, length));\n          contentPosition += length;\n          length = 0;\n        } else {\n          const l = contentItemLength - contentPosition;\n          result.push(Buffer.from(contentItem.buffer, contentItem.byteOffset + contentPosition, l));\n          length -= l;\n          contentPosition = contentItemLength;\n        }\n      } else {\n        if (length >= contentItemLength) {\n          result.push(contentItem);\n          length -= contentItemLength;\n          contentPosition = contentItemLength;\n        } else {\n          result.push(Buffer.from(contentItem.buffer, contentItem.byteOffset, length));\n          contentPosition += length;\n          length = 0;\n        }\n      }\n      while (length > 0) {\n        nextContent();\n        if (length >= contentItemLength) {\n          result.push(contentItem);\n          length -= contentItemLength;\n          contentPosition = contentItemLength;\n        } else {\n          result.push(Buffer.from(contentItem.buffer, contentItem.byteOffset, length));\n          contentPosition += length;\n          length = 0;\n        }\n      }\n    }\n  }\n  return result;\n};\n\n/**\n * @typedef {BufferSerializableType[]} DeserializedType\n * @typedef {true} SerializedType\n * @extends {SerializerMiddleware<DeserializedType, SerializedType>}\n */\nclass FileMiddleware extends SerializerMiddleware {\n  /**\n   * @param {IntermediateFileSystem} fs filesystem\n   * @param {string | Hash} hashFunction hash function to use\n   */\n  constructor(fs) {\n    let hashFunction = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : \"md4\";\n    super();\n    this.fs = fs;\n    this._hashFunction = hashFunction;\n  }\n  /**\n   * @param {DeserializedType} data data\n   * @param {Object} context context object\n   * @returns {SerializedType|Promise<SerializedType>} serialized data\n   */\n  serialize(data, context) {\n    const {\n      filename,\n      extension = \"\"\n    } = context;\n    return new Promise((resolve, reject) => {\n      mkdirp(this.fs, dirname(this.fs, filename), err => {\n        if (err) return reject(err);\n\n        // It's important that we don't touch existing files during serialization\n        // because serialize may read existing files (when deserializing)\n        const allWrittenFiles = new Set();\n        const writeFile = async (name, content, size) => {\n          const file = name ? join(this.fs, filename, `../${name}${extension}`) : filename;\n          await new Promise((resolve, reject) => {\n            let stream = this.fs.createWriteStream(file + \"_\");\n            let compression;\n            if (file.endsWith(\".gz\")) {\n              compression = createGzip({\n                chunkSize: COMPRESSION_CHUNK_SIZE,\n                level: zConstants.Z_BEST_SPEED\n              });\n            } else if (file.endsWith(\".br\")) {\n              compression = createBrotliCompress({\n                chunkSize: COMPRESSION_CHUNK_SIZE,\n                params: {\n                  [zConstants.BROTLI_PARAM_MODE]: zConstants.BROTLI_MODE_TEXT,\n                  [zConstants.BROTLI_PARAM_QUALITY]: 2,\n                  [zConstants.BROTLI_PARAM_DISABLE_LITERAL_CONTEXT_MODELING]: true,\n                  [zConstants.BROTLI_PARAM_SIZE_HINT]: size\n                }\n              });\n            }\n            if (compression) {\n              pipeline(compression, stream, reject);\n              stream = compression;\n              stream.on(\"finish\", () => resolve());\n            } else {\n              stream.on(\"error\", err => reject(err));\n              stream.on(\"finish\", () => resolve());\n            }\n            // split into chunks for WRITE_LIMIT_CHUNK size\n            const chunks = [];\n            for (const b of content) {\n              if (b.length < WRITE_LIMIT_CHUNK) {\n                chunks.push(b);\n              } else {\n                for (let i = 0; i < b.length; i += WRITE_LIMIT_CHUNK) {\n                  chunks.push(b.slice(i, i + WRITE_LIMIT_CHUNK));\n                }\n              }\n            }\n            const len = chunks.length;\n            let i = 0;\n            const batchWrite = err => {\n              // will be handled in \"on\" error handler\n              if (err) return;\n              if (i === len) {\n                stream.end();\n                return;\n              }\n\n              // queue up a batch of chunks up to the write limit\n              // end is exclusive\n              let end = i;\n              let sum = chunks[end++].length;\n              while (end < len) {\n                sum += chunks[end].length;\n                if (sum > WRITE_LIMIT_TOTAL) break;\n                end++;\n              }\n              while (i < end - 1) {\n                stream.write(chunks[i++]);\n              }\n              stream.write(chunks[i++], batchWrite);\n            };\n            batchWrite();\n          });\n          if (name) allWrittenFiles.add(file);\n        };\n        resolve(serialize(this, data, false, writeFile, this._hashFunction).then(async _ref => {\n          let {\n            backgroundJob\n          } = _ref;\n          await backgroundJob;\n\n          // Rename the index file to disallow access during inconsistent file state\n          await new Promise(resolve => this.fs.rename(filename, filename + \".old\", err => {\n            resolve();\n          }));\n\n          // update all written files\n          await Promise.all(Array.from(allWrittenFiles, file => new Promise((resolve, reject) => {\n            this.fs.rename(file + \"_\", file, err => {\n              if (err) return reject(err);\n              resolve();\n            });\n          })));\n\n          // As final step automatically update the index file to have a consistent pack again\n          await new Promise(resolve => {\n            this.fs.rename(filename + \"_\", filename, err => {\n              if (err) return reject(err);\n              resolve();\n            });\n          });\n          return (/** @type {true} */true\n          );\n        }));\n      });\n    });\n  }\n\n  /**\n   * @param {SerializedType} data data\n   * @param {Object} context context object\n   * @returns {DeserializedType|Promise<DeserializedType>} deserialized data\n   */\n  deserialize(data, context) {\n    const {\n      filename,\n      extension = \"\"\n    } = context;\n    const readFile = name => new Promise((resolve, reject) => {\n      const file = name ? join(this.fs, filename, `../${name}${extension}`) : filename;\n      this.fs.stat(file, (err, stats) => {\n        if (err) {\n          reject(err);\n          return;\n        }\n        let remaining = /** @type {number} */stats.size;\n        /** @type {Buffer | undefined} */\n        let currentBuffer;\n        /** @type {number | undefined} */\n        let currentBufferUsed;\n        const buf = [];\n        let decompression;\n        if (file.endsWith(\".gz\")) {\n          decompression = createGunzip({\n            chunkSize: DECOMPRESSION_CHUNK_SIZE\n          });\n        } else if (file.endsWith(\".br\")) {\n          decompression = createBrotliDecompress({\n            chunkSize: DECOMPRESSION_CHUNK_SIZE\n          });\n        }\n        if (decompression) {\n          let newResolve, newReject;\n          resolve(Promise.all([new Promise((rs, rj) => {\n            newResolve = rs;\n            newReject = rj;\n          }), new Promise((resolve, reject) => {\n            decompression.on(\"data\", chunk => buf.push(chunk));\n            decompression.on(\"end\", () => resolve());\n            decompression.on(\"error\", err => reject(err));\n          })]).then(() => buf));\n          resolve = newResolve;\n          reject = newReject;\n        }\n        this.fs.open(file, \"r\", (err, fd) => {\n          if (err) {\n            reject(err);\n            return;\n          }\n          const read = () => {\n            if (currentBuffer === undefined) {\n              currentBuffer = Buffer.allocUnsafeSlow(Math.min(constants.MAX_LENGTH, remaining, decompression ? DECOMPRESSION_CHUNK_SIZE : Infinity));\n              currentBufferUsed = 0;\n            }\n            let readBuffer = currentBuffer;\n            let readOffset = currentBufferUsed;\n            let readLength = currentBuffer.length - currentBufferUsed;\n            // values passed to fs.read must be valid int32 values\n            if (readOffset > 0x7fffffff) {\n              readBuffer = currentBuffer.slice(readOffset);\n              readOffset = 0;\n            }\n            if (readLength > 0x7fffffff) {\n              readLength = 0x7fffffff;\n            }\n            this.fs.read(fd, readBuffer, readOffset, readLength, null, (err, bytesRead) => {\n              if (err) {\n                this.fs.close(fd, () => {\n                  reject(err);\n                });\n                return;\n              }\n              currentBufferUsed += bytesRead;\n              remaining -= bytesRead;\n              if (currentBufferUsed === currentBuffer.length) {\n                if (decompression) {\n                  decompression.write(currentBuffer);\n                } else {\n                  buf.push(currentBuffer);\n                }\n                currentBuffer = undefined;\n                if (remaining === 0) {\n                  if (decompression) {\n                    decompression.end();\n                  }\n                  this.fs.close(fd, err => {\n                    if (err) {\n                      reject(err);\n                      return;\n                    }\n                    resolve(buf);\n                  });\n                  return;\n                }\n              }\n              read();\n            });\n          };\n          read();\n        });\n      });\n    });\n    return deserialize(this, false, readFile);\n  }\n}\nmodule.exports = FileMiddleware;","map":{"version":3,"names":["constants","require","pipeline","createBrotliCompress","createBrotliDecompress","createGzip","createGunzip","zConstants","createHash","dirname","join","mkdirp","memoize","SerializerMiddleware","VERSION","WRITE_LIMIT_TOTAL","WRITE_LIMIT_CHUNK","hashForName","buffers","hashFunction","hash","buf","update","digest","COMPRESSION_CHUNK_SIZE","DECOMPRESSION_CHUNK_SIZE","writeUInt64LE","Buffer","prototype","writeBigUInt64LE","value","offset","BigInt","low","high","writeUInt32LE","readUInt64LE","readBigUInt64LE","Number","readUInt32LE","serialize","middleware","data","name","writeFile","arguments","length","undefined","processedData","resultToLazy","WeakMap","lastBuffers","item","isLazy","Error","serializedInfo","getLazySerializedValue","push","content","options","getLazyOptions","then","result","size","set","backgroundJobs","resolvedData","Promise","all","map","Array","isArray","isBuffer","backgroundJob","nameBuffer","from","allocUnsafe","copy","lazy","get","setLazySerializedValue","lengths","l","b","header","i","writeInt32LE","deserialize","readFile","contents","contentsIndex","contentItem","contentItemLength","contentPosition","nextContent","ensureData","n","remaining","slice","lengthFromNext","concat","readInt32LE","readSlice","buffer","byteLength","version","sectionCount","lastLengthPositive","valuePositive","toString","createLazy","byteOffset","FileMiddleware","constructor","fs","_hashFunction","context","filename","extension","resolve","reject","err","allWrittenFiles","Set","file","stream","createWriteStream","compression","endsWith","chunkSize","level","Z_BEST_SPEED","params","BROTLI_PARAM_MODE","BROTLI_MODE_TEXT","BROTLI_PARAM_QUALITY","BROTLI_PARAM_DISABLE_LITERAL_CONTEXT_MODELING","BROTLI_PARAM_SIZE_HINT","on","chunks","len","batchWrite","end","sum","write","add","_ref","rename","stat","stats","currentBuffer","currentBufferUsed","decompression","newResolve","newReject","rs","rj","chunk","open","fd","read","allocUnsafeSlow","Math","min","MAX_LENGTH","Infinity","readBuffer","readOffset","readLength","bytesRead","close","module","exports"],"sources":["/home/hemanth/react-project/client/node_modules/webpack/lib/serialization/FileMiddleware.js"],"sourcesContent":["/*\n\tMIT License http://www.opensource.org/licenses/mit-license.php\n*/\n\n\"use strict\";\n\nconst { constants } = require(\"buffer\");\nconst { pipeline } = require(\"stream\");\nconst {\n\tcreateBrotliCompress,\n\tcreateBrotliDecompress,\n\tcreateGzip,\n\tcreateGunzip,\n\tconstants: zConstants\n} = require(\"zlib\");\nconst createHash = require(\"../util/createHash\");\nconst { dirname, join, mkdirp } = require(\"../util/fs\");\nconst memoize = require(\"../util/memoize\");\nconst SerializerMiddleware = require(\"./SerializerMiddleware\");\n\n/** @typedef {typeof import(\"../util/Hash\")} Hash */\n/** @typedef {import(\"../util/fs\").IntermediateFileSystem} IntermediateFileSystem */\n/** @typedef {import(\"./types\").BufferSerializableType} BufferSerializableType */\n\n/*\nFormat:\n\nFile -> Header Section*\n\nVersion -> u32\nAmountOfSections -> u32\nSectionSize -> i32 (if less than zero represents lazy value)\n\nHeader -> Version AmountOfSections SectionSize*\n\nBuffer -> n bytes\nSection -> Buffer\n\n*/\n\n// \"wpc\" + 1 in little-endian\nconst VERSION = 0x01637077;\nconst WRITE_LIMIT_TOTAL = 0x7fff0000;\nconst WRITE_LIMIT_CHUNK = 511 * 1024 * 1024;\n\n/**\n * @param {Buffer[]} buffers buffers\n * @param {string | Hash} hashFunction hash function to use\n * @returns {string} hash\n */\nconst hashForName = (buffers, hashFunction) => {\n\tconst hash = createHash(hashFunction);\n\tfor (const buf of buffers) hash.update(buf);\n\treturn /** @type {string} */ (hash.digest(\"hex\"));\n};\n\nconst COMPRESSION_CHUNK_SIZE = 100 * 1024 * 1024;\nconst DECOMPRESSION_CHUNK_SIZE = 100 * 1024 * 1024;\n\nconst writeUInt64LE = Buffer.prototype.writeBigUInt64LE\n\t? (buf, value, offset) => {\n\t\t\tbuf.writeBigUInt64LE(BigInt(value), offset);\n\t  }\n\t: (buf, value, offset) => {\n\t\t\tconst low = value % 0x100000000;\n\t\t\tconst high = (value - low) / 0x100000000;\n\t\t\tbuf.writeUInt32LE(low, offset);\n\t\t\tbuf.writeUInt32LE(high, offset + 4);\n\t  };\n\nconst readUInt64LE = Buffer.prototype.readBigUInt64LE\n\t? (buf, offset) => {\n\t\t\treturn Number(buf.readBigUInt64LE(offset));\n\t  }\n\t: (buf, offset) => {\n\t\t\tconst low = buf.readUInt32LE(offset);\n\t\t\tconst high = buf.readUInt32LE(offset + 4);\n\t\t\treturn high * 0x100000000 + low;\n\t  };\n\n/**\n * @typedef {Object} SerializeResult\n * @property {string | false} name\n * @property {number} size\n * @property {Promise=} backgroundJob\n */\n\n/**\n * @param {FileMiddleware} middleware this\n * @param {BufferSerializableType[] | Promise<BufferSerializableType[]>} data data to be serialized\n * @param {string | boolean} name file base name\n * @param {function(string | false, Buffer[], number): Promise<void>} writeFile writes a file\n * @param {string | Hash} hashFunction hash function to use\n * @returns {Promise<SerializeResult>} resulting file pointer and promise\n */\nconst serialize = async (\n\tmiddleware,\n\tdata,\n\tname,\n\twriteFile,\n\thashFunction = \"md4\"\n) => {\n\t/** @type {(Buffer[] | Buffer | SerializeResult | Promise<SerializeResult>)[]} */\n\tconst processedData = [];\n\t/** @type {WeakMap<SerializeResult, function(): any | Promise<any>>} */\n\tconst resultToLazy = new WeakMap();\n\t/** @type {Buffer[]} */\n\tlet lastBuffers = undefined;\n\tfor (const item of await data) {\n\t\tif (typeof item === \"function\") {\n\t\t\tif (!SerializerMiddleware.isLazy(item))\n\t\t\t\tthrow new Error(\"Unexpected function\");\n\t\t\tif (!SerializerMiddleware.isLazy(item, middleware)) {\n\t\t\t\tthrow new Error(\n\t\t\t\t\t\"Unexpected lazy value with non-this target (can't pass through lazy values)\"\n\t\t\t\t);\n\t\t\t}\n\t\t\tlastBuffers = undefined;\n\t\t\tconst serializedInfo = SerializerMiddleware.getLazySerializedValue(item);\n\t\t\tif (serializedInfo) {\n\t\t\t\tif (typeof serializedInfo === \"function\") {\n\t\t\t\t\tthrow new Error(\n\t\t\t\t\t\t\"Unexpected lazy value with non-this target (can't pass through lazy values)\"\n\t\t\t\t\t);\n\t\t\t\t} else {\n\t\t\t\t\tprocessedData.push(serializedInfo);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tconst content = item();\n\t\t\t\tif (content) {\n\t\t\t\t\tconst options = SerializerMiddleware.getLazyOptions(item);\n\t\t\t\t\tprocessedData.push(\n\t\t\t\t\t\tserialize(\n\t\t\t\t\t\t\tmiddleware,\n\t\t\t\t\t\t\tcontent,\n\t\t\t\t\t\t\t(options && options.name) || true,\n\t\t\t\t\t\t\twriteFile,\n\t\t\t\t\t\t\thashFunction\n\t\t\t\t\t\t).then(result => {\n\t\t\t\t\t\t\t/** @type {any} */ (item).options.size = result.size;\n\t\t\t\t\t\t\tresultToLazy.set(result, item);\n\t\t\t\t\t\t\treturn result;\n\t\t\t\t\t\t})\n\t\t\t\t\t);\n\t\t\t\t} else {\n\t\t\t\t\tthrow new Error(\n\t\t\t\t\t\t\"Unexpected falsy value returned by lazy value function\"\n\t\t\t\t\t);\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (item) {\n\t\t\tif (lastBuffers) {\n\t\t\t\tlastBuffers.push(item);\n\t\t\t} else {\n\t\t\t\tlastBuffers = [item];\n\t\t\t\tprocessedData.push(lastBuffers);\n\t\t\t}\n\t\t} else {\n\t\t\tthrow new Error(\"Unexpected falsy value in items array\");\n\t\t}\n\t}\n\t/** @type {Promise<any>[]} */\n\tconst backgroundJobs = [];\n\tconst resolvedData = (\n\t\tawait Promise.all(\n\t\t\t/** @type {Promise<Buffer[] | Buffer | SerializeResult>[]} */ (\n\t\t\t\tprocessedData\n\t\t\t)\n\t\t)\n\t).map(item => {\n\t\tif (Array.isArray(item) || Buffer.isBuffer(item)) return item;\n\n\t\tbackgroundJobs.push(item.backgroundJob);\n\t\t// create pointer buffer from size and name\n\t\tconst name = /** @type {string} */ (item.name);\n\t\tconst nameBuffer = Buffer.from(name);\n\t\tconst buf = Buffer.allocUnsafe(8 + nameBuffer.length);\n\t\twriteUInt64LE(buf, item.size, 0);\n\t\tnameBuffer.copy(buf, 8, 0);\n\t\tconst lazy = resultToLazy.get(item);\n\t\tSerializerMiddleware.setLazySerializedValue(lazy, buf);\n\t\treturn buf;\n\t});\n\t/** @type {number[]} */\n\tconst lengths = [];\n\tfor (const item of resolvedData) {\n\t\tif (Array.isArray(item)) {\n\t\t\tlet l = 0;\n\t\t\tfor (const b of item) l += b.length;\n\t\t\twhile (l > 0x7fffffff) {\n\t\t\t\tlengths.push(0x7fffffff);\n\t\t\t\tl -= 0x7fffffff;\n\t\t\t}\n\t\t\tlengths.push(l);\n\t\t} else if (item) {\n\t\t\tlengths.push(-item.length);\n\t\t} else {\n\t\t\tthrow new Error(\"Unexpected falsy value in resolved data \" + item);\n\t\t}\n\t}\n\tconst header = Buffer.allocUnsafe(8 + lengths.length * 4);\n\theader.writeUInt32LE(VERSION, 0);\n\theader.writeUInt32LE(lengths.length, 4);\n\tfor (let i = 0; i < lengths.length; i++) {\n\t\theader.writeInt32LE(lengths[i], 8 + i * 4);\n\t}\n\t/** @type {Buffer[]} */\n\tconst buf = [header];\n\tfor (const item of resolvedData) {\n\t\tif (Array.isArray(item)) {\n\t\t\tfor (const b of item) buf.push(b);\n\t\t} else if (item) {\n\t\t\tbuf.push(item);\n\t\t}\n\t}\n\tif (name === true) {\n\t\tname = hashForName(buf, hashFunction);\n\t}\n\tlet size = 0;\n\tfor (const b of buf) size += b.length;\n\tbackgroundJobs.push(writeFile(name, buf, size));\n\treturn {\n\t\tsize,\n\t\tname,\n\t\tbackgroundJob:\n\t\t\tbackgroundJobs.length === 1\n\t\t\t\t? backgroundJobs[0]\n\t\t\t\t: Promise.all(backgroundJobs)\n\t};\n};\n\n/**\n * @param {FileMiddleware} middleware this\n * @param {string | false} name filename\n * @param {function(string | false): Promise<Buffer[]>} readFile read content of a file\n * @returns {Promise<BufferSerializableType[]>} deserialized data\n */\nconst deserialize = async (middleware, name, readFile) => {\n\tconst contents = await readFile(name);\n\tif (contents.length === 0) throw new Error(\"Empty file \" + name);\n\tlet contentsIndex = 0;\n\tlet contentItem = contents[0];\n\tlet contentItemLength = contentItem.length;\n\tlet contentPosition = 0;\n\tif (contentItemLength === 0) throw new Error(\"Empty file \" + name);\n\tconst nextContent = () => {\n\t\tcontentsIndex++;\n\t\tcontentItem = contents[contentsIndex];\n\t\tcontentItemLength = contentItem.length;\n\t\tcontentPosition = 0;\n\t};\n\t/**\n\t * @param {number} n number of bytes to ensure\n\t */\n\tconst ensureData = n => {\n\t\tif (contentPosition === contentItemLength) {\n\t\t\tnextContent();\n\t\t}\n\t\twhile (contentItemLength - contentPosition < n) {\n\t\t\tconst remaining = contentItem.slice(contentPosition);\n\t\t\tlet lengthFromNext = n - remaining.length;\n\t\t\tconst buffers = [remaining];\n\t\t\tfor (let i = contentsIndex + 1; i < contents.length; i++) {\n\t\t\t\tconst l = contents[i].length;\n\t\t\t\tif (l > lengthFromNext) {\n\t\t\t\t\tbuffers.push(contents[i].slice(0, lengthFromNext));\n\t\t\t\t\tcontents[i] = contents[i].slice(lengthFromNext);\n\t\t\t\t\tlengthFromNext = 0;\n\t\t\t\t\tbreak;\n\t\t\t\t} else {\n\t\t\t\t\tbuffers.push(contents[i]);\n\t\t\t\t\tcontentsIndex = i;\n\t\t\t\t\tlengthFromNext -= l;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (lengthFromNext > 0) throw new Error(\"Unexpected end of data\");\n\t\t\tcontentItem = Buffer.concat(buffers, n);\n\t\t\tcontentItemLength = n;\n\t\t\tcontentPosition = 0;\n\t\t}\n\t};\n\t/**\n\t * @returns {number} value value\n\t */\n\tconst readUInt32LE = () => {\n\t\tensureData(4);\n\t\tconst value = contentItem.readUInt32LE(contentPosition);\n\t\tcontentPosition += 4;\n\t\treturn value;\n\t};\n\t/**\n\t * @returns {number} value value\n\t */\n\tconst readInt32LE = () => {\n\t\tensureData(4);\n\t\tconst value = contentItem.readInt32LE(contentPosition);\n\t\tcontentPosition += 4;\n\t\treturn value;\n\t};\n\t/**\n\t * @param {number} l length\n\t * @returns {Buffer} buffer\n\t */\n\tconst readSlice = l => {\n\t\tensureData(l);\n\t\tif (contentPosition === 0 && contentItemLength === l) {\n\t\t\tconst result = contentItem;\n\t\t\tif (contentsIndex + 1 < contents.length) {\n\t\t\t\tnextContent();\n\t\t\t} else {\n\t\t\t\tcontentPosition = l;\n\t\t\t}\n\t\t\treturn result;\n\t\t}\n\t\tconst result = contentItem.slice(contentPosition, contentPosition + l);\n\t\tcontentPosition += l;\n\t\t// we clone the buffer here to allow the original content to be garbage collected\n\t\treturn l * 2 < contentItem.buffer.byteLength ? Buffer.from(result) : result;\n\t};\n\tconst version = readUInt32LE();\n\tif (version !== VERSION) {\n\t\tthrow new Error(\"Invalid file version\");\n\t}\n\tconst sectionCount = readUInt32LE();\n\tconst lengths = [];\n\tlet lastLengthPositive = false;\n\tfor (let i = 0; i < sectionCount; i++) {\n\t\tconst value = readInt32LE();\n\t\tconst valuePositive = value >= 0;\n\t\tif (lastLengthPositive && valuePositive) {\n\t\t\tlengths[lengths.length - 1] += value;\n\t\t} else {\n\t\t\tlengths.push(value);\n\t\t\tlastLengthPositive = valuePositive;\n\t\t}\n\t}\n\tconst result = [];\n\tfor (let length of lengths) {\n\t\tif (length < 0) {\n\t\t\tconst slice = readSlice(-length);\n\t\t\tconst size = Number(readUInt64LE(slice, 0));\n\t\t\tconst nameBuffer = slice.slice(8);\n\t\t\tconst name = nameBuffer.toString();\n\t\t\tresult.push(\n\t\t\t\tSerializerMiddleware.createLazy(\n\t\t\t\t\tmemoize(() => deserialize(middleware, name, readFile)),\n\t\t\t\t\tmiddleware,\n\t\t\t\t\t{\n\t\t\t\t\t\tname,\n\t\t\t\t\t\tsize\n\t\t\t\t\t},\n\t\t\t\t\tslice\n\t\t\t\t)\n\t\t\t);\n\t\t} else {\n\t\t\tif (contentPosition === contentItemLength) {\n\t\t\t\tnextContent();\n\t\t\t} else if (contentPosition !== 0) {\n\t\t\t\tif (length <= contentItemLength - contentPosition) {\n\t\t\t\t\tresult.push(\n\t\t\t\t\t\tBuffer.from(\n\t\t\t\t\t\t\tcontentItem.buffer,\n\t\t\t\t\t\t\tcontentItem.byteOffset + contentPosition,\n\t\t\t\t\t\t\tlength\n\t\t\t\t\t\t)\n\t\t\t\t\t);\n\t\t\t\t\tcontentPosition += length;\n\t\t\t\t\tlength = 0;\n\t\t\t\t} else {\n\t\t\t\t\tconst l = contentItemLength - contentPosition;\n\t\t\t\t\tresult.push(\n\t\t\t\t\t\tBuffer.from(\n\t\t\t\t\t\t\tcontentItem.buffer,\n\t\t\t\t\t\t\tcontentItem.byteOffset + contentPosition,\n\t\t\t\t\t\t\tl\n\t\t\t\t\t\t)\n\t\t\t\t\t);\n\t\t\t\t\tlength -= l;\n\t\t\t\t\tcontentPosition = contentItemLength;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (length >= contentItemLength) {\n\t\t\t\t\tresult.push(contentItem);\n\t\t\t\t\tlength -= contentItemLength;\n\t\t\t\t\tcontentPosition = contentItemLength;\n\t\t\t\t} else {\n\t\t\t\t\tresult.push(\n\t\t\t\t\t\tBuffer.from(contentItem.buffer, contentItem.byteOffset, length)\n\t\t\t\t\t);\n\t\t\t\t\tcontentPosition += length;\n\t\t\t\t\tlength = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t\twhile (length > 0) {\n\t\t\t\tnextContent();\n\t\t\t\tif (length >= contentItemLength) {\n\t\t\t\t\tresult.push(contentItem);\n\t\t\t\t\tlength -= contentItemLength;\n\t\t\t\t\tcontentPosition = contentItemLength;\n\t\t\t\t} else {\n\t\t\t\t\tresult.push(\n\t\t\t\t\t\tBuffer.from(contentItem.buffer, contentItem.byteOffset, length)\n\t\t\t\t\t);\n\t\t\t\t\tcontentPosition += length;\n\t\t\t\t\tlength = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn result;\n};\n\n/**\n * @typedef {BufferSerializableType[]} DeserializedType\n * @typedef {true} SerializedType\n * @extends {SerializerMiddleware<DeserializedType, SerializedType>}\n */\nclass FileMiddleware extends SerializerMiddleware {\n\t/**\n\t * @param {IntermediateFileSystem} fs filesystem\n\t * @param {string | Hash} hashFunction hash function to use\n\t */\n\tconstructor(fs, hashFunction = \"md4\") {\n\t\tsuper();\n\t\tthis.fs = fs;\n\t\tthis._hashFunction = hashFunction;\n\t}\n\t/**\n\t * @param {DeserializedType} data data\n\t * @param {Object} context context object\n\t * @returns {SerializedType|Promise<SerializedType>} serialized data\n\t */\n\tserialize(data, context) {\n\t\tconst { filename, extension = \"\" } = context;\n\t\treturn new Promise((resolve, reject) => {\n\t\t\tmkdirp(this.fs, dirname(this.fs, filename), err => {\n\t\t\t\tif (err) return reject(err);\n\n\t\t\t\t// It's important that we don't touch existing files during serialization\n\t\t\t\t// because serialize may read existing files (when deserializing)\n\t\t\t\tconst allWrittenFiles = new Set();\n\t\t\t\tconst writeFile = async (name, content, size) => {\n\t\t\t\t\tconst file = name\n\t\t\t\t\t\t? join(this.fs, filename, `../${name}${extension}`)\n\t\t\t\t\t\t: filename;\n\t\t\t\t\tawait new Promise((resolve, reject) => {\n\t\t\t\t\t\tlet stream = this.fs.createWriteStream(file + \"_\");\n\t\t\t\t\t\tlet compression;\n\t\t\t\t\t\tif (file.endsWith(\".gz\")) {\n\t\t\t\t\t\t\tcompression = createGzip({\n\t\t\t\t\t\t\t\tchunkSize: COMPRESSION_CHUNK_SIZE,\n\t\t\t\t\t\t\t\tlevel: zConstants.Z_BEST_SPEED\n\t\t\t\t\t\t\t});\n\t\t\t\t\t\t} else if (file.endsWith(\".br\")) {\n\t\t\t\t\t\t\tcompression = createBrotliCompress({\n\t\t\t\t\t\t\t\tchunkSize: COMPRESSION_CHUNK_SIZE,\n\t\t\t\t\t\t\t\tparams: {\n\t\t\t\t\t\t\t\t\t[zConstants.BROTLI_PARAM_MODE]: zConstants.BROTLI_MODE_TEXT,\n\t\t\t\t\t\t\t\t\t[zConstants.BROTLI_PARAM_QUALITY]: 2,\n\t\t\t\t\t\t\t\t\t[zConstants.BROTLI_PARAM_DISABLE_LITERAL_CONTEXT_MODELING]: true,\n\t\t\t\t\t\t\t\t\t[zConstants.BROTLI_PARAM_SIZE_HINT]: size\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t});\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (compression) {\n\t\t\t\t\t\t\tpipeline(compression, stream, reject);\n\t\t\t\t\t\t\tstream = compression;\n\t\t\t\t\t\t\tstream.on(\"finish\", () => resolve());\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tstream.on(\"error\", err => reject(err));\n\t\t\t\t\t\t\tstream.on(\"finish\", () => resolve());\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// split into chunks for WRITE_LIMIT_CHUNK size\n\t\t\t\t\t\tconst chunks = [];\n\t\t\t\t\t\tfor (const b of content) {\n\t\t\t\t\t\t\tif (b.length < WRITE_LIMIT_CHUNK) {\n\t\t\t\t\t\t\t\tchunks.push(b);\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tfor (let i = 0; i < b.length; i += WRITE_LIMIT_CHUNK) {\n\t\t\t\t\t\t\t\t\tchunks.push(b.slice(i, i + WRITE_LIMIT_CHUNK));\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tconst len = chunks.length;\n\t\t\t\t\t\tlet i = 0;\n\t\t\t\t\t\tconst batchWrite = err => {\n\t\t\t\t\t\t\t// will be handled in \"on\" error handler\n\t\t\t\t\t\t\tif (err) return;\n\n\t\t\t\t\t\t\tif (i === len) {\n\t\t\t\t\t\t\t\tstream.end();\n\t\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// queue up a batch of chunks up to the write limit\n\t\t\t\t\t\t\t// end is exclusive\n\t\t\t\t\t\t\tlet end = i;\n\t\t\t\t\t\t\tlet sum = chunks[end++].length;\n\t\t\t\t\t\t\twhile (end < len) {\n\t\t\t\t\t\t\t\tsum += chunks[end].length;\n\t\t\t\t\t\t\t\tif (sum > WRITE_LIMIT_TOTAL) break;\n\t\t\t\t\t\t\t\tend++;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\twhile (i < end - 1) {\n\t\t\t\t\t\t\t\tstream.write(chunks[i++]);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tstream.write(chunks[i++], batchWrite);\n\t\t\t\t\t\t};\n\t\t\t\t\t\tbatchWrite();\n\t\t\t\t\t});\n\t\t\t\t\tif (name) allWrittenFiles.add(file);\n\t\t\t\t};\n\n\t\t\t\tresolve(\n\t\t\t\t\tserialize(this, data, false, writeFile, this._hashFunction).then(\n\t\t\t\t\t\tasync ({ backgroundJob }) => {\n\t\t\t\t\t\t\tawait backgroundJob;\n\n\t\t\t\t\t\t\t// Rename the index file to disallow access during inconsistent file state\n\t\t\t\t\t\t\tawait new Promise(resolve =>\n\t\t\t\t\t\t\t\tthis.fs.rename(filename, filename + \".old\", err => {\n\t\t\t\t\t\t\t\t\tresolve();\n\t\t\t\t\t\t\t\t})\n\t\t\t\t\t\t\t);\n\n\t\t\t\t\t\t\t// update all written files\n\t\t\t\t\t\t\tawait Promise.all(\n\t\t\t\t\t\t\t\tArray.from(\n\t\t\t\t\t\t\t\t\tallWrittenFiles,\n\t\t\t\t\t\t\t\t\tfile =>\n\t\t\t\t\t\t\t\t\t\tnew Promise((resolve, reject) => {\n\t\t\t\t\t\t\t\t\t\t\tthis.fs.rename(file + \"_\", file, err => {\n\t\t\t\t\t\t\t\t\t\t\t\tif (err) return reject(err);\n\t\t\t\t\t\t\t\t\t\t\t\tresolve();\n\t\t\t\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\t\t\t})\n\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t);\n\n\t\t\t\t\t\t\t// As final step automatically update the index file to have a consistent pack again\n\t\t\t\t\t\t\tawait new Promise(resolve => {\n\t\t\t\t\t\t\t\tthis.fs.rename(filename + \"_\", filename, err => {\n\t\t\t\t\t\t\t\t\tif (err) return reject(err);\n\t\t\t\t\t\t\t\t\tresolve();\n\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\treturn /** @type {true} */ (true);\n\t\t\t\t\t\t}\n\t\t\t\t\t)\n\t\t\t\t);\n\t\t\t});\n\t\t});\n\t}\n\n\t/**\n\t * @param {SerializedType} data data\n\t * @param {Object} context context object\n\t * @returns {DeserializedType|Promise<DeserializedType>} deserialized data\n\t */\n\tdeserialize(data, context) {\n\t\tconst { filename, extension = \"\" } = context;\n\t\tconst readFile = name =>\n\t\t\tnew Promise((resolve, reject) => {\n\t\t\t\tconst file = name\n\t\t\t\t\t? join(this.fs, filename, `../${name}${extension}`)\n\t\t\t\t\t: filename;\n\t\t\t\tthis.fs.stat(file, (err, stats) => {\n\t\t\t\t\tif (err) {\n\t\t\t\t\t\treject(err);\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t\tlet remaining = /** @type {number} */ (stats.size);\n\t\t\t\t\t/** @type {Buffer | undefined} */\n\t\t\t\t\tlet currentBuffer;\n\t\t\t\t\t/** @type {number | undefined} */\n\t\t\t\t\tlet currentBufferUsed;\n\t\t\t\t\tconst buf = [];\n\t\t\t\t\tlet decompression;\n\t\t\t\t\tif (file.endsWith(\".gz\")) {\n\t\t\t\t\t\tdecompression = createGunzip({\n\t\t\t\t\t\t\tchunkSize: DECOMPRESSION_CHUNK_SIZE\n\t\t\t\t\t\t});\n\t\t\t\t\t} else if (file.endsWith(\".br\")) {\n\t\t\t\t\t\tdecompression = createBrotliDecompress({\n\t\t\t\t\t\t\tchunkSize: DECOMPRESSION_CHUNK_SIZE\n\t\t\t\t\t\t});\n\t\t\t\t\t}\n\t\t\t\t\tif (decompression) {\n\t\t\t\t\t\tlet newResolve, newReject;\n\t\t\t\t\t\tresolve(\n\t\t\t\t\t\t\tPromise.all([\n\t\t\t\t\t\t\t\tnew Promise((rs, rj) => {\n\t\t\t\t\t\t\t\t\tnewResolve = rs;\n\t\t\t\t\t\t\t\t\tnewReject = rj;\n\t\t\t\t\t\t\t\t}),\n\t\t\t\t\t\t\t\tnew Promise((resolve, reject) => {\n\t\t\t\t\t\t\t\t\tdecompression.on(\"data\", chunk => buf.push(chunk));\n\t\t\t\t\t\t\t\t\tdecompression.on(\"end\", () => resolve());\n\t\t\t\t\t\t\t\t\tdecompression.on(\"error\", err => reject(err));\n\t\t\t\t\t\t\t\t})\n\t\t\t\t\t\t\t]).then(() => buf)\n\t\t\t\t\t\t);\n\t\t\t\t\t\tresolve = newResolve;\n\t\t\t\t\t\treject = newReject;\n\t\t\t\t\t}\n\t\t\t\t\tthis.fs.open(file, \"r\", (err, fd) => {\n\t\t\t\t\t\tif (err) {\n\t\t\t\t\t\t\treject(err);\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tconst read = () => {\n\t\t\t\t\t\t\tif (currentBuffer === undefined) {\n\t\t\t\t\t\t\t\tcurrentBuffer = Buffer.allocUnsafeSlow(\n\t\t\t\t\t\t\t\t\tMath.min(\n\t\t\t\t\t\t\t\t\t\tconstants.MAX_LENGTH,\n\t\t\t\t\t\t\t\t\t\tremaining,\n\t\t\t\t\t\t\t\t\t\tdecompression ? DECOMPRESSION_CHUNK_SIZE : Infinity\n\t\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t\t);\n\t\t\t\t\t\t\t\tcurrentBufferUsed = 0;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tlet readBuffer = currentBuffer;\n\t\t\t\t\t\t\tlet readOffset = currentBufferUsed;\n\t\t\t\t\t\t\tlet readLength = currentBuffer.length - currentBufferUsed;\n\t\t\t\t\t\t\t// values passed to fs.read must be valid int32 values\n\t\t\t\t\t\t\tif (readOffset > 0x7fffffff) {\n\t\t\t\t\t\t\t\treadBuffer = currentBuffer.slice(readOffset);\n\t\t\t\t\t\t\t\treadOffset = 0;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (readLength > 0x7fffffff) {\n\t\t\t\t\t\t\t\treadLength = 0x7fffffff;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tthis.fs.read(\n\t\t\t\t\t\t\t\tfd,\n\t\t\t\t\t\t\t\treadBuffer,\n\t\t\t\t\t\t\t\treadOffset,\n\t\t\t\t\t\t\t\treadLength,\n\t\t\t\t\t\t\t\tnull,\n\t\t\t\t\t\t\t\t(err, bytesRead) => {\n\t\t\t\t\t\t\t\t\tif (err) {\n\t\t\t\t\t\t\t\t\t\tthis.fs.close(fd, () => {\n\t\t\t\t\t\t\t\t\t\t\treject(err);\n\t\t\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\tcurrentBufferUsed += bytesRead;\n\t\t\t\t\t\t\t\t\tremaining -= bytesRead;\n\t\t\t\t\t\t\t\t\tif (currentBufferUsed === currentBuffer.length) {\n\t\t\t\t\t\t\t\t\t\tif (decompression) {\n\t\t\t\t\t\t\t\t\t\t\tdecompression.write(currentBuffer);\n\t\t\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\t\t\tbuf.push(currentBuffer);\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\tcurrentBuffer = undefined;\n\t\t\t\t\t\t\t\t\t\tif (remaining === 0) {\n\t\t\t\t\t\t\t\t\t\t\tif (decompression) {\n\t\t\t\t\t\t\t\t\t\t\t\tdecompression.end();\n\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\tthis.fs.close(fd, err => {\n\t\t\t\t\t\t\t\t\t\t\t\tif (err) {\n\t\t\t\t\t\t\t\t\t\t\t\t\treject(err);\n\t\t\t\t\t\t\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\t\tresolve(buf);\n\t\t\t\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\tread();\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t);\n\t\t\t\t\t\t};\n\t\t\t\t\t\tread();\n\t\t\t\t\t});\n\t\t\t\t});\n\t\t\t});\n\t\treturn deserialize(this, false, readFile);\n\t}\n}\n\nmodule.exports = FileMiddleware;\n"],"mappings":"AAAA;AACA;AACA;;AAEA,YAAY;;AAEZ,MAAM;EAAEA;AAAU,CAAC,GAAGC,OAAO,CAAC,QAAQ,CAAC;AACvC,MAAM;EAAEC;AAAS,CAAC,GAAGD,OAAO,CAAC,QAAQ,CAAC;AACtC,MAAM;EACLE,oBAAoB;EACpBC,sBAAsB;EACtBC,UAAU;EACVC,YAAY;EACZN,SAAS,EAAEO;AACZ,CAAC,GAAGN,OAAO,CAAC,MAAM,CAAC;AACnB,MAAMO,UAAU,GAAGP,OAAO,CAAC,oBAAoB,CAAC;AAChD,MAAM;EAAEQ,OAAO;EAAEC,IAAI;EAAEC;AAAO,CAAC,GAAGV,OAAO,CAAC,YAAY,CAAC;AACvD,MAAMW,OAAO,GAAGX,OAAO,CAAC,iBAAiB,CAAC;AAC1C,MAAMY,oBAAoB,GAAGZ,OAAO,CAAC,wBAAwB,CAAC;;AAE9D;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,MAAMa,OAAO,GAAG,UAAU;AAC1B,MAAMC,iBAAiB,GAAG,UAAU;AACpC,MAAMC,iBAAiB,GAAG,GAAG,GAAG,IAAI,GAAG,IAAI;;AAE3C;AACA;AACA;AACA;AACA;AACA,MAAMC,WAAW,GAAGA,CAACC,OAAO,EAAEC,YAAY,KAAK;EAC9C,MAAMC,IAAI,GAAGZ,UAAU,CAACW,YAAY,CAAC;EACrC,KAAK,MAAME,GAAG,IAAIH,OAAO,EAAEE,IAAI,CAACE,MAAM,CAACD,GAAG,CAAC;EAC3C,OAAO,sBAAuBD,IAAI,CAACG,MAAM,CAAC,KAAK;EAAC;AACjD,CAAC;AAED,MAAMC,sBAAsB,GAAG,GAAG,GAAG,IAAI,GAAG,IAAI;AAChD,MAAMC,wBAAwB,GAAG,GAAG,GAAG,IAAI,GAAG,IAAI;AAElD,MAAMC,aAAa,GAAGC,MAAM,CAACC,SAAS,CAACC,gBAAgB,GACpD,CAACR,GAAG,EAAES,KAAK,EAAEC,MAAM,KAAK;EACxBV,GAAG,CAACQ,gBAAgB,CAACG,MAAM,CAACF,KAAK,CAAC,EAAEC,MAAM,CAAC;AAC3C,CAAC,GACD,CAACV,GAAG,EAAES,KAAK,EAAEC,MAAM,KAAK;EACxB,MAAME,GAAG,GAAGH,KAAK,GAAG,WAAW;EAC/B,MAAMI,IAAI,GAAG,CAACJ,KAAK,GAAGG,GAAG,IAAI,WAAW;EACxCZ,GAAG,CAACc,aAAa,CAACF,GAAG,EAAEF,MAAM,CAAC;EAC9BV,GAAG,CAACc,aAAa,CAACD,IAAI,EAAEH,MAAM,GAAG,CAAC,CAAC;AACnC,CAAC;AAEJ,MAAMK,YAAY,GAAGT,MAAM,CAACC,SAAS,CAACS,eAAe,GAClD,CAAChB,GAAG,EAAEU,MAAM,KAAK;EACjB,OAAOO,MAAM,CAACjB,GAAG,CAACgB,eAAe,CAACN,MAAM,CAAC,CAAC;AAC1C,CAAC,GACD,CAACV,GAAG,EAAEU,MAAM,KAAK;EACjB,MAAME,GAAG,GAAGZ,GAAG,CAACkB,YAAY,CAACR,MAAM,CAAC;EACpC,MAAMG,IAAI,GAAGb,GAAG,CAACkB,YAAY,CAACR,MAAM,GAAG,CAAC,CAAC;EACzC,OAAOG,IAAI,GAAG,WAAW,GAAGD,GAAG;AAC/B,CAAC;;AAEJ;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAMO,SAAS,GAAG,eAAAA,CACjBC,UAAU,EACVC,IAAI,EACJC,IAAI,EACJC,SAAS,EAEL;EAAA,IADJzB,YAAY,GAAA0B,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;EAEpB;EACA,MAAMG,aAAa,GAAG,EAAE;EACxB;EACA,MAAMC,YAAY,GAAG,IAAIC,OAAO,CAAC,CAAC;EAClC;EACA,IAAIC,WAAW,GAAGJ,SAAS;EAC3B,KAAK,MAAMK,IAAI,IAAI,MAAMV,IAAI,EAAE;IAC9B,IAAI,OAAOU,IAAI,KAAK,UAAU,EAAE;MAC/B,IAAI,CAACvC,oBAAoB,CAACwC,MAAM,CAACD,IAAI,CAAC,EACrC,MAAM,IAAIE,KAAK,CAAC,qBAAqB,CAAC;MACvC,IAAI,CAACzC,oBAAoB,CAACwC,MAAM,CAACD,IAAI,EAAEX,UAAU,CAAC,EAAE;QACnD,MAAM,IAAIa,KAAK,CACd,6EACD,CAAC;MACF;MACAH,WAAW,GAAGJ,SAAS;MACvB,MAAMQ,cAAc,GAAG1C,oBAAoB,CAAC2C,sBAAsB,CAACJ,IAAI,CAAC;MACxE,IAAIG,cAAc,EAAE;QACnB,IAAI,OAAOA,cAAc,KAAK,UAAU,EAAE;UACzC,MAAM,IAAID,KAAK,CACd,6EACD,CAAC;QACF,CAAC,MAAM;UACNN,aAAa,CAACS,IAAI,CAACF,cAAc,CAAC;QACnC;MACD,CAAC,MAAM;QACN,MAAMG,OAAO,GAAGN,IAAI,CAAC,CAAC;QACtB,IAAIM,OAAO,EAAE;UACZ,MAAMC,OAAO,GAAG9C,oBAAoB,CAAC+C,cAAc,CAACR,IAAI,CAAC;UACzDJ,aAAa,CAACS,IAAI,CACjBjB,SAAS,CACRC,UAAU,EACViB,OAAO,EACNC,OAAO,IAAIA,OAAO,CAAChB,IAAI,IAAK,IAAI,EACjCC,SAAS,EACTzB,YACD,CAAC,CAAC0C,IAAI,CAACC,MAAM,IAAI;YAChB,kBAAoBV,IAAI,CAAEO,OAAO,CAACI,IAAI,GAAGD,MAAM,CAACC,IAAI;YACpDd,YAAY,CAACe,GAAG,CAACF,MAAM,EAAEV,IAAI,CAAC;YAC9B,OAAOU,MAAM;UACd,CAAC,CACF,CAAC;QACF,CAAC,MAAM;UACN,MAAM,IAAIR,KAAK,CACd,wDACD,CAAC;QACF;MACD;IACD,CAAC,MAAM,IAAIF,IAAI,EAAE;MAChB,IAAID,WAAW,EAAE;QAChBA,WAAW,CAACM,IAAI,CAACL,IAAI,CAAC;MACvB,CAAC,MAAM;QACND,WAAW,GAAG,CAACC,IAAI,CAAC;QACpBJ,aAAa,CAACS,IAAI,CAACN,WAAW,CAAC;MAChC;IACD,CAAC,MAAM;MACN,MAAM,IAAIG,KAAK,CAAC,uCAAuC,CAAC;IACzD;EACD;EACA;EACA,MAAMW,cAAc,GAAG,EAAE;EACzB,MAAMC,YAAY,GAAG,CACpB,MAAMC,OAAO,CAACC,GAAG,EAChB;EACCpB,aAEF,CAAC,EACAqB,GAAG,CAACjB,IAAI,IAAI;IACb,IAAIkB,KAAK,CAACC,OAAO,CAACnB,IAAI,CAAC,IAAIzB,MAAM,CAAC6C,QAAQ,CAACpB,IAAI,CAAC,EAAE,OAAOA,IAAI;IAE7Da,cAAc,CAACR,IAAI,CAACL,IAAI,CAACqB,aAAa,CAAC;IACvC;IACA,MAAM9B,IAAI,GAAG,qBAAuBS,IAAI,CAACT,IAAK;IAC9C,MAAM+B,UAAU,GAAG/C,MAAM,CAACgD,IAAI,CAAChC,IAAI,CAAC;IACpC,MAAMtB,GAAG,GAAGM,MAAM,CAACiD,WAAW,CAAC,CAAC,GAAGF,UAAU,CAAC5B,MAAM,CAAC;IACrDpB,aAAa,CAACL,GAAG,EAAE+B,IAAI,CAACW,IAAI,EAAE,CAAC,CAAC;IAChCW,UAAU,CAACG,IAAI,CAACxD,GAAG,EAAE,CAAC,EAAE,CAAC,CAAC;IAC1B,MAAMyD,IAAI,GAAG7B,YAAY,CAAC8B,GAAG,CAAC3B,IAAI,CAAC;IACnCvC,oBAAoB,CAACmE,sBAAsB,CAACF,IAAI,EAAEzD,GAAG,CAAC;IACtD,OAAOA,GAAG;EACX,CAAC,CAAC;EACF;EACA,MAAM4D,OAAO,GAAG,EAAE;EAClB,KAAK,MAAM7B,IAAI,IAAIc,YAAY,EAAE;IAChC,IAAII,KAAK,CAACC,OAAO,CAACnB,IAAI,CAAC,EAAE;MACxB,IAAI8B,CAAC,GAAG,CAAC;MACT,KAAK,MAAMC,CAAC,IAAI/B,IAAI,EAAE8B,CAAC,IAAIC,CAAC,CAACrC,MAAM;MACnC,OAAOoC,CAAC,GAAG,UAAU,EAAE;QACtBD,OAAO,CAACxB,IAAI,CAAC,UAAU,CAAC;QACxByB,CAAC,IAAI,UAAU;MAChB;MACAD,OAAO,CAACxB,IAAI,CAACyB,CAAC,CAAC;IAChB,CAAC,MAAM,IAAI9B,IAAI,EAAE;MAChB6B,OAAO,CAACxB,IAAI,CAAC,CAACL,IAAI,CAACN,MAAM,CAAC;IAC3B,CAAC,MAAM;MACN,MAAM,IAAIQ,KAAK,CAAC,0CAA0C,GAAGF,IAAI,CAAC;IACnE;EACD;EACA,MAAMgC,MAAM,GAAGzD,MAAM,CAACiD,WAAW,CAAC,CAAC,GAAGK,OAAO,CAACnC,MAAM,GAAG,CAAC,CAAC;EACzDsC,MAAM,CAACjD,aAAa,CAACrB,OAAO,EAAE,CAAC,CAAC;EAChCsE,MAAM,CAACjD,aAAa,CAAC8C,OAAO,CAACnC,MAAM,EAAE,CAAC,CAAC;EACvC,KAAK,IAAIuC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGJ,OAAO,CAACnC,MAAM,EAAEuC,CAAC,EAAE,EAAE;IACxCD,MAAM,CAACE,YAAY,CAACL,OAAO,CAACI,CAAC,CAAC,EAAE,CAAC,GAAGA,CAAC,GAAG,CAAC,CAAC;EAC3C;EACA;EACA,MAAMhE,GAAG,GAAG,CAAC+D,MAAM,CAAC;EACpB,KAAK,MAAMhC,IAAI,IAAIc,YAAY,EAAE;IAChC,IAAII,KAAK,CAACC,OAAO,CAACnB,IAAI,CAAC,EAAE;MACxB,KAAK,MAAM+B,CAAC,IAAI/B,IAAI,EAAE/B,GAAG,CAACoC,IAAI,CAAC0B,CAAC,CAAC;IAClC,CAAC,MAAM,IAAI/B,IAAI,EAAE;MAChB/B,GAAG,CAACoC,IAAI,CAACL,IAAI,CAAC;IACf;EACD;EACA,IAAIT,IAAI,KAAK,IAAI,EAAE;IAClBA,IAAI,GAAG1B,WAAW,CAACI,GAAG,EAAEF,YAAY,CAAC;EACtC;EACA,IAAI4C,IAAI,GAAG,CAAC;EACZ,KAAK,MAAMoB,CAAC,IAAI9D,GAAG,EAAE0C,IAAI,IAAIoB,CAAC,CAACrC,MAAM;EACrCmB,cAAc,CAACR,IAAI,CAACb,SAAS,CAACD,IAAI,EAAEtB,GAAG,EAAE0C,IAAI,CAAC,CAAC;EAC/C,OAAO;IACNA,IAAI;IACJpB,IAAI;IACJ8B,aAAa,EACZR,cAAc,CAACnB,MAAM,KAAK,CAAC,GACxBmB,cAAc,CAAC,CAAC,CAAC,GACjBE,OAAO,CAACC,GAAG,CAACH,cAAc;EAC/B,CAAC;AACF,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA,MAAMsB,WAAW,GAAG,MAAAA,CAAO9C,UAAU,EAAEE,IAAI,EAAE6C,QAAQ,KAAK;EACzD,MAAMC,QAAQ,GAAG,MAAMD,QAAQ,CAAC7C,IAAI,CAAC;EACrC,IAAI8C,QAAQ,CAAC3C,MAAM,KAAK,CAAC,EAAE,MAAM,IAAIQ,KAAK,CAAC,aAAa,GAAGX,IAAI,CAAC;EAChE,IAAI+C,aAAa,GAAG,CAAC;EACrB,IAAIC,WAAW,GAAGF,QAAQ,CAAC,CAAC,CAAC;EAC7B,IAAIG,iBAAiB,GAAGD,WAAW,CAAC7C,MAAM;EAC1C,IAAI+C,eAAe,GAAG,CAAC;EACvB,IAAID,iBAAiB,KAAK,CAAC,EAAE,MAAM,IAAItC,KAAK,CAAC,aAAa,GAAGX,IAAI,CAAC;EAClE,MAAMmD,WAAW,GAAGA,CAAA,KAAM;IACzBJ,aAAa,EAAE;IACfC,WAAW,GAAGF,QAAQ,CAACC,aAAa,CAAC;IACrCE,iBAAiB,GAAGD,WAAW,CAAC7C,MAAM;IACtC+C,eAAe,GAAG,CAAC;EACpB,CAAC;EACD;AACD;AACA;EACC,MAAME,UAAU,GAAGC,CAAC,IAAI;IACvB,IAAIH,eAAe,KAAKD,iBAAiB,EAAE;MAC1CE,WAAW,CAAC,CAAC;IACd;IACA,OAAOF,iBAAiB,GAAGC,eAAe,GAAGG,CAAC,EAAE;MAC/C,MAAMC,SAAS,GAAGN,WAAW,CAACO,KAAK,CAACL,eAAe,CAAC;MACpD,IAAIM,cAAc,GAAGH,CAAC,GAAGC,SAAS,CAACnD,MAAM;MACzC,MAAM5B,OAAO,GAAG,CAAC+E,SAAS,CAAC;MAC3B,KAAK,IAAIZ,CAAC,GAAGK,aAAa,GAAG,CAAC,EAAEL,CAAC,GAAGI,QAAQ,CAAC3C,MAAM,EAAEuC,CAAC,EAAE,EAAE;QACzD,MAAMH,CAAC,GAAGO,QAAQ,CAACJ,CAAC,CAAC,CAACvC,MAAM;QAC5B,IAAIoC,CAAC,GAAGiB,cAAc,EAAE;UACvBjF,OAAO,CAACuC,IAAI,CAACgC,QAAQ,CAACJ,CAAC,CAAC,CAACa,KAAK,CAAC,CAAC,EAAEC,cAAc,CAAC,CAAC;UAClDV,QAAQ,CAACJ,CAAC,CAAC,GAAGI,QAAQ,CAACJ,CAAC,CAAC,CAACa,KAAK,CAACC,cAAc,CAAC;UAC/CA,cAAc,GAAG,CAAC;UAClB;QACD,CAAC,MAAM;UACNjF,OAAO,CAACuC,IAAI,CAACgC,QAAQ,CAACJ,CAAC,CAAC,CAAC;UACzBK,aAAa,GAAGL,CAAC;UACjBc,cAAc,IAAIjB,CAAC;QACpB;MACD;MACA,IAAIiB,cAAc,GAAG,CAAC,EAAE,MAAM,IAAI7C,KAAK,CAAC,wBAAwB,CAAC;MACjEqC,WAAW,GAAGhE,MAAM,CAACyE,MAAM,CAAClF,OAAO,EAAE8E,CAAC,CAAC;MACvCJ,iBAAiB,GAAGI,CAAC;MACrBH,eAAe,GAAG,CAAC;IACpB;EACD,CAAC;EACD;AACD;AACA;EACC,MAAMtD,YAAY,GAAGA,CAAA,KAAM;IAC1BwD,UAAU,CAAC,CAAC,CAAC;IACb,MAAMjE,KAAK,GAAG6D,WAAW,CAACpD,YAAY,CAACsD,eAAe,CAAC;IACvDA,eAAe,IAAI,CAAC;IACpB,OAAO/D,KAAK;EACb,CAAC;EACD;AACD;AACA;EACC,MAAMuE,WAAW,GAAGA,CAAA,KAAM;IACzBN,UAAU,CAAC,CAAC,CAAC;IACb,MAAMjE,KAAK,GAAG6D,WAAW,CAACU,WAAW,CAACR,eAAe,CAAC;IACtDA,eAAe,IAAI,CAAC;IACpB,OAAO/D,KAAK;EACb,CAAC;EACD;AACD;AACA;AACA;EACC,MAAMwE,SAAS,GAAGpB,CAAC,IAAI;IACtBa,UAAU,CAACb,CAAC,CAAC;IACb,IAAIW,eAAe,KAAK,CAAC,IAAID,iBAAiB,KAAKV,CAAC,EAAE;MACrD,MAAMpB,MAAM,GAAG6B,WAAW;MAC1B,IAAID,aAAa,GAAG,CAAC,GAAGD,QAAQ,CAAC3C,MAAM,EAAE;QACxCgD,WAAW,CAAC,CAAC;MACd,CAAC,MAAM;QACND,eAAe,GAAGX,CAAC;MACpB;MACA,OAAOpB,MAAM;IACd;IACA,MAAMA,MAAM,GAAG6B,WAAW,CAACO,KAAK,CAACL,eAAe,EAAEA,eAAe,GAAGX,CAAC,CAAC;IACtEW,eAAe,IAAIX,CAAC;IACpB;IACA,OAAOA,CAAC,GAAG,CAAC,GAAGS,WAAW,CAACY,MAAM,CAACC,UAAU,GAAG7E,MAAM,CAACgD,IAAI,CAACb,MAAM,CAAC,GAAGA,MAAM;EAC5E,CAAC;EACD,MAAM2C,OAAO,GAAGlE,YAAY,CAAC,CAAC;EAC9B,IAAIkE,OAAO,KAAK3F,OAAO,EAAE;IACxB,MAAM,IAAIwC,KAAK,CAAC,sBAAsB,CAAC;EACxC;EACA,MAAMoD,YAAY,GAAGnE,YAAY,CAAC,CAAC;EACnC,MAAM0C,OAAO,GAAG,EAAE;EAClB,IAAI0B,kBAAkB,GAAG,KAAK;EAC9B,KAAK,IAAItB,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGqB,YAAY,EAAErB,CAAC,EAAE,EAAE;IACtC,MAAMvD,KAAK,GAAGuE,WAAW,CAAC,CAAC;IAC3B,MAAMO,aAAa,GAAG9E,KAAK,IAAI,CAAC;IAChC,IAAI6E,kBAAkB,IAAIC,aAAa,EAAE;MACxC3B,OAAO,CAACA,OAAO,CAACnC,MAAM,GAAG,CAAC,CAAC,IAAIhB,KAAK;IACrC,CAAC,MAAM;MACNmD,OAAO,CAACxB,IAAI,CAAC3B,KAAK,CAAC;MACnB6E,kBAAkB,GAAGC,aAAa;IACnC;EACD;EACA,MAAM9C,MAAM,GAAG,EAAE;EACjB,KAAK,IAAIhB,MAAM,IAAImC,OAAO,EAAE;IAC3B,IAAInC,MAAM,GAAG,CAAC,EAAE;MACf,MAAMoD,KAAK,GAAGI,SAAS,CAAC,CAACxD,MAAM,CAAC;MAChC,MAAMiB,IAAI,GAAGzB,MAAM,CAACF,YAAY,CAAC8D,KAAK,EAAE,CAAC,CAAC,CAAC;MAC3C,MAAMxB,UAAU,GAAGwB,KAAK,CAACA,KAAK,CAAC,CAAC,CAAC;MACjC,MAAMvD,IAAI,GAAG+B,UAAU,CAACmC,QAAQ,CAAC,CAAC;MAClC/C,MAAM,CAACL,IAAI,CACV5C,oBAAoB,CAACiG,UAAU,CAC9BlG,OAAO,CAAC,MAAM2E,WAAW,CAAC9C,UAAU,EAAEE,IAAI,EAAE6C,QAAQ,CAAC,CAAC,EACtD/C,UAAU,EACV;QACCE,IAAI;QACJoB;MACD,CAAC,EACDmC,KACD,CACD,CAAC;IACF,CAAC,MAAM;MACN,IAAIL,eAAe,KAAKD,iBAAiB,EAAE;QAC1CE,WAAW,CAAC,CAAC;MACd,CAAC,MAAM,IAAID,eAAe,KAAK,CAAC,EAAE;QACjC,IAAI/C,MAAM,IAAI8C,iBAAiB,GAAGC,eAAe,EAAE;UAClD/B,MAAM,CAACL,IAAI,CACV9B,MAAM,CAACgD,IAAI,CACVgB,WAAW,CAACY,MAAM,EAClBZ,WAAW,CAACoB,UAAU,GAAGlB,eAAe,EACxC/C,MACD,CACD,CAAC;UACD+C,eAAe,IAAI/C,MAAM;UACzBA,MAAM,GAAG,CAAC;QACX,CAAC,MAAM;UACN,MAAMoC,CAAC,GAAGU,iBAAiB,GAAGC,eAAe;UAC7C/B,MAAM,CAACL,IAAI,CACV9B,MAAM,CAACgD,IAAI,CACVgB,WAAW,CAACY,MAAM,EAClBZ,WAAW,CAACoB,UAAU,GAAGlB,eAAe,EACxCX,CACD,CACD,CAAC;UACDpC,MAAM,IAAIoC,CAAC;UACXW,eAAe,GAAGD,iBAAiB;QACpC;MACD,CAAC,MAAM;QACN,IAAI9C,MAAM,IAAI8C,iBAAiB,EAAE;UAChC9B,MAAM,CAACL,IAAI,CAACkC,WAAW,CAAC;UACxB7C,MAAM,IAAI8C,iBAAiB;UAC3BC,eAAe,GAAGD,iBAAiB;QACpC,CAAC,MAAM;UACN9B,MAAM,CAACL,IAAI,CACV9B,MAAM,CAACgD,IAAI,CAACgB,WAAW,CAACY,MAAM,EAAEZ,WAAW,CAACoB,UAAU,EAAEjE,MAAM,CAC/D,CAAC;UACD+C,eAAe,IAAI/C,MAAM;UACzBA,MAAM,GAAG,CAAC;QACX;MACD;MACA,OAAOA,MAAM,GAAG,CAAC,EAAE;QAClBgD,WAAW,CAAC,CAAC;QACb,IAAIhD,MAAM,IAAI8C,iBAAiB,EAAE;UAChC9B,MAAM,CAACL,IAAI,CAACkC,WAAW,CAAC;UACxB7C,MAAM,IAAI8C,iBAAiB;UAC3BC,eAAe,GAAGD,iBAAiB;QACpC,CAAC,MAAM;UACN9B,MAAM,CAACL,IAAI,CACV9B,MAAM,CAACgD,IAAI,CAACgB,WAAW,CAACY,MAAM,EAAEZ,WAAW,CAACoB,UAAU,EAAEjE,MAAM,CAC/D,CAAC;UACD+C,eAAe,IAAI/C,MAAM;UACzBA,MAAM,GAAG,CAAC;QACX;MACD;IACD;EACD;EACA,OAAOgB,MAAM;AACd,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA,MAAMkD,cAAc,SAASnG,oBAAoB,CAAC;EACjD;AACD;AACA;AACA;EACCoG,WAAWA,CAACC,EAAE,EAAwB;IAAA,IAAtB/F,YAAY,GAAA0B,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,KAAK;IACnC,KAAK,CAAC,CAAC;IACP,IAAI,CAACqE,EAAE,GAAGA,EAAE;IACZ,IAAI,CAACC,aAAa,GAAGhG,YAAY;EAClC;EACA;AACD;AACA;AACA;AACA;EACCqB,SAASA,CAACE,IAAI,EAAE0E,OAAO,EAAE;IACxB,MAAM;MAAEC,QAAQ;MAAEC,SAAS,GAAG;IAAG,CAAC,GAAGF,OAAO;IAC5C,OAAO,IAAIjD,OAAO,CAAC,CAACoD,OAAO,EAAEC,MAAM,KAAK;MACvC7G,MAAM,CAAC,IAAI,CAACuG,EAAE,EAAEzG,OAAO,CAAC,IAAI,CAACyG,EAAE,EAAEG,QAAQ,CAAC,EAAEI,GAAG,IAAI;QAClD,IAAIA,GAAG,EAAE,OAAOD,MAAM,CAACC,GAAG,CAAC;;QAE3B;QACA;QACA,MAAMC,eAAe,GAAG,IAAIC,GAAG,CAAC,CAAC;QACjC,MAAM/E,SAAS,GAAG,MAAAA,CAAOD,IAAI,EAAEe,OAAO,EAAEK,IAAI,KAAK;UAChD,MAAM6D,IAAI,GAAGjF,IAAI,GACdjC,IAAI,CAAC,IAAI,CAACwG,EAAE,EAAEG,QAAQ,EAAG,MAAK1E,IAAK,GAAE2E,SAAU,EAAC,CAAC,GACjDD,QAAQ;UACX,MAAM,IAAIlD,OAAO,CAAC,CAACoD,OAAO,EAAEC,MAAM,KAAK;YACtC,IAAIK,MAAM,GAAG,IAAI,CAACX,EAAE,CAACY,iBAAiB,CAACF,IAAI,GAAG,GAAG,CAAC;YAClD,IAAIG,WAAW;YACf,IAAIH,IAAI,CAACI,QAAQ,CAAC,KAAK,CAAC,EAAE;cACzBD,WAAW,GAAG1H,UAAU,CAAC;gBACxB4H,SAAS,EAAEzG,sBAAsB;gBACjC0G,KAAK,EAAE3H,UAAU,CAAC4H;cACnB,CAAC,CAAC;YACH,CAAC,MAAM,IAAIP,IAAI,CAACI,QAAQ,CAAC,KAAK,CAAC,EAAE;cAChCD,WAAW,GAAG5H,oBAAoB,CAAC;gBAClC8H,SAAS,EAAEzG,sBAAsB;gBACjC4G,MAAM,EAAE;kBACP,CAAC7H,UAAU,CAAC8H,iBAAiB,GAAG9H,UAAU,CAAC+H,gBAAgB;kBAC3D,CAAC/H,UAAU,CAACgI,oBAAoB,GAAG,CAAC;kBACpC,CAAChI,UAAU,CAACiI,6CAA6C,GAAG,IAAI;kBAChE,CAACjI,UAAU,CAACkI,sBAAsB,GAAG1E;gBACtC;cACD,CAAC,CAAC;YACH;YACA,IAAIgE,WAAW,EAAE;cAChB7H,QAAQ,CAAC6H,WAAW,EAAEF,MAAM,EAAEL,MAAM,CAAC;cACrCK,MAAM,GAAGE,WAAW;cACpBF,MAAM,CAACa,EAAE,CAAC,QAAQ,EAAE,MAAMnB,OAAO,CAAC,CAAC,CAAC;YACrC,CAAC,MAAM;cACNM,MAAM,CAACa,EAAE,CAAC,OAAO,EAAEjB,GAAG,IAAID,MAAM,CAACC,GAAG,CAAC,CAAC;cACtCI,MAAM,CAACa,EAAE,CAAC,QAAQ,EAAE,MAAMnB,OAAO,CAAC,CAAC,CAAC;YACrC;YACA;YACA,MAAMoB,MAAM,GAAG,EAAE;YACjB,KAAK,MAAMxD,CAAC,IAAIzB,OAAO,EAAE;cACxB,IAAIyB,CAAC,CAACrC,MAAM,GAAG9B,iBAAiB,EAAE;gBACjC2H,MAAM,CAAClF,IAAI,CAAC0B,CAAC,CAAC;cACf,CAAC,MAAM;gBACN,KAAK,IAAIE,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGF,CAAC,CAACrC,MAAM,EAAEuC,CAAC,IAAIrE,iBAAiB,EAAE;kBACrD2H,MAAM,CAAClF,IAAI,CAAC0B,CAAC,CAACe,KAAK,CAACb,CAAC,EAAEA,CAAC,GAAGrE,iBAAiB,CAAC,CAAC;gBAC/C;cACD;YACD;YAEA,MAAM4H,GAAG,GAAGD,MAAM,CAAC7F,MAAM;YACzB,IAAIuC,CAAC,GAAG,CAAC;YACT,MAAMwD,UAAU,GAAGpB,GAAG,IAAI;cACzB;cACA,IAAIA,GAAG,EAAE;cAET,IAAIpC,CAAC,KAAKuD,GAAG,EAAE;gBACdf,MAAM,CAACiB,GAAG,CAAC,CAAC;gBACZ;cACD;;cAEA;cACA;cACA,IAAIA,GAAG,GAAGzD,CAAC;cACX,IAAI0D,GAAG,GAAGJ,MAAM,CAACG,GAAG,EAAE,CAAC,CAAChG,MAAM;cAC9B,OAAOgG,GAAG,GAAGF,GAAG,EAAE;gBACjBG,GAAG,IAAIJ,MAAM,CAACG,GAAG,CAAC,CAAChG,MAAM;gBACzB,IAAIiG,GAAG,GAAGhI,iBAAiB,EAAE;gBAC7B+H,GAAG,EAAE;cACN;cACA,OAAOzD,CAAC,GAAGyD,GAAG,GAAG,CAAC,EAAE;gBACnBjB,MAAM,CAACmB,KAAK,CAACL,MAAM,CAACtD,CAAC,EAAE,CAAC,CAAC;cAC1B;cACAwC,MAAM,CAACmB,KAAK,CAACL,MAAM,CAACtD,CAAC,EAAE,CAAC,EAAEwD,UAAU,CAAC;YACtC,CAAC;YACDA,UAAU,CAAC,CAAC;UACb,CAAC,CAAC;UACF,IAAIlG,IAAI,EAAE+E,eAAe,CAACuB,GAAG,CAACrB,IAAI,CAAC;QACpC,CAAC;QAEDL,OAAO,CACN/E,SAAS,CAAC,IAAI,EAAEE,IAAI,EAAE,KAAK,EAAEE,SAAS,EAAE,IAAI,CAACuE,aAAa,CAAC,CAACtD,IAAI,CAC/D,MAAAqF,IAAA,IAA6B;UAAA,IAAtB;YAAEzE;UAAc,CAAC,GAAAyE,IAAA;UACvB,MAAMzE,aAAa;;UAEnB;UACA,MAAM,IAAIN,OAAO,CAACoD,OAAO,IACxB,IAAI,CAACL,EAAE,CAACiC,MAAM,CAAC9B,QAAQ,EAAEA,QAAQ,GAAG,MAAM,EAAEI,GAAG,IAAI;YAClDF,OAAO,CAAC,CAAC;UACV,CAAC,CACF,CAAC;;UAED;UACA,MAAMpD,OAAO,CAACC,GAAG,CAChBE,KAAK,CAACK,IAAI,CACT+C,eAAe,EACfE,IAAI,IACH,IAAIzD,OAAO,CAAC,CAACoD,OAAO,EAAEC,MAAM,KAAK;YAChC,IAAI,CAACN,EAAE,CAACiC,MAAM,CAACvB,IAAI,GAAG,GAAG,EAAEA,IAAI,EAAEH,GAAG,IAAI;cACvC,IAAIA,GAAG,EAAE,OAAOD,MAAM,CAACC,GAAG,CAAC;cAC3BF,OAAO,CAAC,CAAC;YACV,CAAC,CAAC;UACH,CAAC,CACH,CACD,CAAC;;UAED;UACA,MAAM,IAAIpD,OAAO,CAACoD,OAAO,IAAI;YAC5B,IAAI,CAACL,EAAE,CAACiC,MAAM,CAAC9B,QAAQ,GAAG,GAAG,EAAEA,QAAQ,EAAEI,GAAG,IAAI;cAC/C,IAAIA,GAAG,EAAE,OAAOD,MAAM,CAACC,GAAG,CAAC;cAC3BF,OAAO,CAAC,CAAC;YACV,CAAC,CAAC;UACH,CAAC,CAAC;UACF,OAAO,oBAAqB;UAAI;QACjC,CACD,CACD,CAAC;MACF,CAAC,CAAC;IACH,CAAC,CAAC;EACH;;EAEA;AACD;AACA;AACA;AACA;EACChC,WAAWA,CAAC7C,IAAI,EAAE0E,OAAO,EAAE;IAC1B,MAAM;MAAEC,QAAQ;MAAEC,SAAS,GAAG;IAAG,CAAC,GAAGF,OAAO;IAC5C,MAAM5B,QAAQ,GAAG7C,IAAI,IACpB,IAAIwB,OAAO,CAAC,CAACoD,OAAO,EAAEC,MAAM,KAAK;MAChC,MAAMI,IAAI,GAAGjF,IAAI,GACdjC,IAAI,CAAC,IAAI,CAACwG,EAAE,EAAEG,QAAQ,EAAG,MAAK1E,IAAK,GAAE2E,SAAU,EAAC,CAAC,GACjDD,QAAQ;MACX,IAAI,CAACH,EAAE,CAACkC,IAAI,CAACxB,IAAI,EAAE,CAACH,GAAG,EAAE4B,KAAK,KAAK;QAClC,IAAI5B,GAAG,EAAE;UACRD,MAAM,CAACC,GAAG,CAAC;UACX;QACD;QACA,IAAIxB,SAAS,GAAG,qBAAuBoD,KAAK,CAACtF,IAAK;QAClD;QACA,IAAIuF,aAAa;QACjB;QACA,IAAIC,iBAAiB;QACrB,MAAMlI,GAAG,GAAG,EAAE;QACd,IAAImI,aAAa;QACjB,IAAI5B,IAAI,CAACI,QAAQ,CAAC,KAAK,CAAC,EAAE;UACzBwB,aAAa,GAAGlJ,YAAY,CAAC;YAC5B2H,SAAS,EAAExG;UACZ,CAAC,CAAC;QACH,CAAC,MAAM,IAAImG,IAAI,CAACI,QAAQ,CAAC,KAAK,CAAC,EAAE;UAChCwB,aAAa,GAAGpJ,sBAAsB,CAAC;YACtC6H,SAAS,EAAExG;UACZ,CAAC,CAAC;QACH;QACA,IAAI+H,aAAa,EAAE;UAClB,IAAIC,UAAU,EAAEC,SAAS;UACzBnC,OAAO,CACNpD,OAAO,CAACC,GAAG,CAAC,CACX,IAAID,OAAO,CAAC,CAACwF,EAAE,EAAEC,EAAE,KAAK;YACvBH,UAAU,GAAGE,EAAE;YACfD,SAAS,GAAGE,EAAE;UACf,CAAC,CAAC,EACF,IAAIzF,OAAO,CAAC,CAACoD,OAAO,EAAEC,MAAM,KAAK;YAChCgC,aAAa,CAACd,EAAE,CAAC,MAAM,EAAEmB,KAAK,IAAIxI,GAAG,CAACoC,IAAI,CAACoG,KAAK,CAAC,CAAC;YAClDL,aAAa,CAACd,EAAE,CAAC,KAAK,EAAE,MAAMnB,OAAO,CAAC,CAAC,CAAC;YACxCiC,aAAa,CAACd,EAAE,CAAC,OAAO,EAAEjB,GAAG,IAAID,MAAM,CAACC,GAAG,CAAC,CAAC;UAC9C,CAAC,CAAC,CACF,CAAC,CAAC5D,IAAI,CAAC,MAAMxC,GAAG,CAClB,CAAC;UACDkG,OAAO,GAAGkC,UAAU;UACpBjC,MAAM,GAAGkC,SAAS;QACnB;QACA,IAAI,CAACxC,EAAE,CAAC4C,IAAI,CAAClC,IAAI,EAAE,GAAG,EAAE,CAACH,GAAG,EAAEsC,EAAE,KAAK;UACpC,IAAItC,GAAG,EAAE;YACRD,MAAM,CAACC,GAAG,CAAC;YACX;UACD;UACA,MAAMuC,IAAI,GAAGA,CAAA,KAAM;YAClB,IAAIV,aAAa,KAAKvG,SAAS,EAAE;cAChCuG,aAAa,GAAG3H,MAAM,CAACsI,eAAe,CACrCC,IAAI,CAACC,GAAG,CACPnK,SAAS,CAACoK,UAAU,EACpBnE,SAAS,EACTuD,aAAa,GAAG/H,wBAAwB,GAAG4I,QAC5C,CACD,CAAC;cACDd,iBAAiB,GAAG,CAAC;YACtB;YACA,IAAIe,UAAU,GAAGhB,aAAa;YAC9B,IAAIiB,UAAU,GAAGhB,iBAAiB;YAClC,IAAIiB,UAAU,GAAGlB,aAAa,CAACxG,MAAM,GAAGyG,iBAAiB;YACzD;YACA,IAAIgB,UAAU,GAAG,UAAU,EAAE;cAC5BD,UAAU,GAAGhB,aAAa,CAACpD,KAAK,CAACqE,UAAU,CAAC;cAC5CA,UAAU,GAAG,CAAC;YACf;YACA,IAAIC,UAAU,GAAG,UAAU,EAAE;cAC5BA,UAAU,GAAG,UAAU;YACxB;YACA,IAAI,CAACtD,EAAE,CAAC8C,IAAI,CACXD,EAAE,EACFO,UAAU,EACVC,UAAU,EACVC,UAAU,EACV,IAAI,EACJ,CAAC/C,GAAG,EAAEgD,SAAS,KAAK;cACnB,IAAIhD,GAAG,EAAE;gBACR,IAAI,CAACP,EAAE,CAACwD,KAAK,CAACX,EAAE,EAAE,MAAM;kBACvBvC,MAAM,CAACC,GAAG,CAAC;gBACZ,CAAC,CAAC;gBACF;cACD;cACA8B,iBAAiB,IAAIkB,SAAS;cAC9BxE,SAAS,IAAIwE,SAAS;cACtB,IAAIlB,iBAAiB,KAAKD,aAAa,CAACxG,MAAM,EAAE;gBAC/C,IAAI0G,aAAa,EAAE;kBAClBA,aAAa,CAACR,KAAK,CAACM,aAAa,CAAC;gBACnC,CAAC,MAAM;kBACNjI,GAAG,CAACoC,IAAI,CAAC6F,aAAa,CAAC;gBACxB;gBACAA,aAAa,GAAGvG,SAAS;gBACzB,IAAIkD,SAAS,KAAK,CAAC,EAAE;kBACpB,IAAIuD,aAAa,EAAE;oBAClBA,aAAa,CAACV,GAAG,CAAC,CAAC;kBACpB;kBACA,IAAI,CAAC5B,EAAE,CAACwD,KAAK,CAACX,EAAE,EAAEtC,GAAG,IAAI;oBACxB,IAAIA,GAAG,EAAE;sBACRD,MAAM,CAACC,GAAG,CAAC;sBACX;oBACD;oBACAF,OAAO,CAAClG,GAAG,CAAC;kBACb,CAAC,CAAC;kBACF;gBACD;cACD;cACA2I,IAAI,CAAC,CAAC;YACP,CACD,CAAC;UACF,CAAC;UACDA,IAAI,CAAC,CAAC;QACP,CAAC,CAAC;MACH,CAAC,CAAC;IACH,CAAC,CAAC;IACH,OAAOzE,WAAW,CAAC,IAAI,EAAE,KAAK,EAAEC,QAAQ,CAAC;EAC1C;AACD;AAEAmF,MAAM,CAACC,OAAO,GAAG5D,cAAc"},"metadata":{},"sourceType":"script","externalDependencies":[]}